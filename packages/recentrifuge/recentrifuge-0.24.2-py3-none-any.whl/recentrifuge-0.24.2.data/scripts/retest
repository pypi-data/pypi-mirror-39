#!python
#
#     Copyright (C) 2018, Jose Manuel Martí Martínez
#
#     This program is free software: you can redistribute it and/or modify
#     it under the terms of the GNU Affero General Public License as
#     published by the Free Software Foundation, either version 3 of the
#     License, or (at your option) any later version.
#
#     This program is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
#     GNU Affero General Public License for more details.
#
#     You should have received a copy of the GNU Affero General Public License
#     along with this program. If not, see <https://www.gnu.org/licenses/>.
#
"""
Launch tests for the whole Recentrifuge package.

Meaning of retest exit codes:
 Code   Explanation
 ----   ----------------------------------------------
    0   All tests passed
    1   Problem with required dependencies
    2   Failed the version check
    3   Failed the retaxdump test
    4   Failed the remock test
    5   Failed the recentrifuge test
    >5  Failed a multiple comparison between test data and test standard
"""

import argparse
import os
import re
import subprocess as sp
import sys
import time

from distutils.version import StrictVersion

from recentrifuge import __version__, __author__, __date__, __path__
from recentrifuge.config import Filename, Score, Extra
from recentrifuge.config import LICENSE, TAXDUMP_PATH, HTML_SUFFIX, XLSX_SUFFIX
from recentrifuge.config import STATS_SHEET_NAME, TEST_OUTPUT_DIR
from recentrifuge.config import gray, blue, magenta, green, red

# pandas (to read Excel with mock layout)
try:
    import pandas as pd
    if StrictVersion(pd.__version__) < StrictVersion('0.23.2'):
        print(red('ERROR!'), 'Please upgrade pandas to v0.23.2 or higher for '
                             'testing recentrifuge.')
        sys.exit(1)
except ImportError:
    pd = None
    print(red('ERROR!'), 'Please install pandas (v0.23.2 or higher) for '
                         'testing recentrifuge.')
    sys.exit(1)

# Local constants
MHL_DEFAULT = 35
EPS = 1e-16  # Local epsilon for floating point comparisons
F_V = '-V'
F_TAX = '-n=' + TAXDUMP_PATH
PATH = os.path.dirname(os.path.realpath(__file__))
PATH_TEST: Filename = Filename(os.path.join(__path__[0], 'test/'))
F_FIL = '-f=' + TEST_OUTPUT_DIR
TEST_PREFIX = 'TEST'
HTML_FIL: Filename = TEST_PREFIX + HTML_SUFFIX
XLSX_FIL: Filename = TEST_PREFIX + XLSX_SUFFIX
F_OUT = '-o=' + os.path.join(TEST_OUTPUT_DIR, HTML_FIL)
F_CTR = '-c=3'
F_MHL = '-y='
F_RND = '-r='
F_MIN = '-m=5'
F_G = '-g'
F_T = '-t'
F_CC = '-e=CMPLXCRUNCHER'

XLSX_PATH: Filename = Filename(os.path.join(TEST_OUTPUT_DIR, XLSX_FIL))
STND_PATH: Filename = Filename(os.path.join(PATH_TEST, XLSX_FIL))


def main():
    """Main entry point to script."""

    def configure_parser():
        """Argument Parser Configuration"""
        parser = argparse.ArgumentParser(
            description='Launch Recentrifuge tests',
            epilog=f'%(prog)s  - Release {__version__} - {__date__}' + LICENSE,
            formatter_class=argparse.RawDescriptionHelpFormatter
        )
        parser.add_argument(
            '-g', '--debug',
            action='store_true',
            help='increase output verbosity and perform additional checks'
        )
        parser.add_argument(
            '-i', '--ignore',
            action='store_true',
            help='continue testing even if errors arise'
        )
        parser.add_argument(
            '-l', '--local',
            action='store_true',
            help='test local directory scripts instead of pip installed'
        )
        parser.add_argument(
            '-y', '--minscore',
            action='store',
            metavar='NUMBER',
            type=lambda txt: Score(float(txt)),
            default=Score(MHL_DEFAULT),
            help=('minimum score/confidence of the classification of a read '
                  f'to pass the quality filter; {MHL_DEFAULT} by default')
        )
        parser.add_argument(
            '-V', '--version',
            action='version',
            version=f'%(prog)s release {__version__} ({__date__})'
        )
        return parser

    def check_debug():
        """Check debugging mode"""
        if args.debug:
            print(blue('INFO:'), gray('Debugging mode activated'))
            print(blue('INFO:'), gray('Active parameters:'))
            for key, value in vars(args).items():
                if value:
                    print(gray(f'\t{key} ='), f'{value}')
            print(blue('INFO:'), gray('Relevant paths:'))
            for var in ['TAXDUMP_PATH', 'PATH', 'PATH_TEST',
                        'XLSX_PATH', 'STND_PATH']:
                print(gray(f'\t{var} ='), f'{eval(var)}')

    # Timing initialization
    start_time: float = time.time()

    # Program header
    print(f'\n=-= {sys.argv[0]} =-= v{__version__} - {__date__}'
          f' =-= by {__author__} =-=\n')
    sys.stdout.flush()

    # Parse arguments
    argparser = configure_parser()
    args = argparser.parse_args()
    minscore: Score = args.minscore
    prefix: Filename = Filename('')
    if args.local:
        prefix = Filename('./')

    check_debug()

    prog: Filename = Filename(prefix + 'rcf')
    print(magenta(f'\n>>> TESTING VERSION ... '), end='')
    sys.stdout.flush()
    cproc = sp.run([prog, F_V], stdout=sp.PIPE, stderr=sp.STDOUT,
                   universal_newlines=True)
    match = re.search(r'(\d+\.\d+\.\d+[a-z]*\d*)\s', cproc.stdout)
    if match.group(1) == __version__:
        print(green('OK!'))
    else:
        print(red('FAILED!'))
        print(blue('INFO:'), f'Installed recentrifuge is v{match.group(1)} '
        f'while these tests are for version {__version__}')
        if not args.ignore:
            sys.exit(2)

    prog = Filename(prefix + 'retaxdump')
    print(magenta(f'\n>>> TESTING {prog} ...'))
    sys.stdout.flush()
    cproc = sp.run([prog], universal_newlines=True)
    print(magenta(f'\n<<< END {prog} TEST: '), end='')
    if cproc.returncode == 0:
        print(green('OK!'))
    else:
        print(red('FAILED!'))
        if not args.ignore:
            sys.exit(3)

    prog = Filename(prefix + 'remock')
    print(magenta(f'\n>>> TESTING {prog} ...'))
    argums = [prog, F_TAX, F_RND + str(minscore), F_T, F_G]
    cproc = sp.run(argums, universal_newlines=True)
    print(magenta(f'\n<<< END {prog} TEST: '), end='')
    if cproc.returncode == 0:
        print(green('OK!'))
    else:
        print(red('FAILED!'))
        if not args.ignore:
            sys.exit(4)

    prog = Filename(prefix + 'rcf')
    print(magenta(f'\n>>> TESTING {prog} ...'))
    argums = [prog, F_TAX, F_FIL, F_OUT, F_CTR, F_MHL + str(minscore),
              F_MIN, F_G]
    cproc = sp.run(argums, universal_newlines=True)
    print(magenta(f'\n<<< END {prog} TEST: '), end='')
    if cproc.returncode == 0:
        print(green('OK!'))
    else:
        print(red('FAILED!'))
        if not args.ignore:
            sys.exit(5)

    print(magenta(f'\n>>> COMPARING {prog} RESULTS WITH STANDARD:'))
    for sheet in [STATS_SHEET_NAME, str(Extra.FULL)]:
        print(magenta(f'>> TEST FOR {sheet}... '), end='')
        pd_stnd = pd.ExcelFile(STND_PATH)
        df_stat_stnd = pd_stnd.parse(
            sheet_name=sheet, header=0,
            skiprows=None, index_col=0
        )

        pd_xlsx = pd.ExcelFile(XLSX_PATH)
        df_stat_xlsx = pd_xlsx.parse(
            sheet_name=sheet, header=0,
            skiprows=None, index_col=0
        )
        df_stat_xlsx.columns = df_stat_stnd.columns
        if df_stat_xlsx.equals(df_stat_stnd):
            print(green('OK!'))
        else:
            print(red('FAILED!'))
            print('Difference between test results and test standard?')
            print(df_stat_xlsx.where(df_stat_xlsx != df_stat_stnd, False))
            if not args.ignore:
                sys.exit(6)

    # Timing results
    print(gray('Total test time:'), time.strftime(
        "%H:%M:%S", time.gmtime(time.time() - start_time)))


if __name__ == '__main__':
    main()
