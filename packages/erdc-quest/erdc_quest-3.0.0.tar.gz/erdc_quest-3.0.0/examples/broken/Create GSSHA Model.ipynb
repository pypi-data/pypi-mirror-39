{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation Instructions\n",
    "\n",
    "Clone the repos, install dependencies and install packages terrapin, quest and gsshapy.\n",
    "\n",
    "Note: terrapin isn't used in this example but it will be in future examples...\n",
    "\n",
    "```bash\n",
    "git clone git@public.git.erdc.dren.mil:computational-analysis-and-mechanics/quest.git\n",
    "git clone git@public.git.erdc.dren.mil:computational-analysis-and-mechanics/terrapin.git\n",
    "git clone git@github.com:CI-WATER/gsshapy.git\n",
    "\n",
    "conda env create -n earthsim -f ./terrapin/py3_conda_environment.yml\n",
    "conda env update -n earthsim -f ./quest/py3_conda_environment.yml\n",
    "conda env update -n earthsim -f ./gsshapy/conda_env.yml\n",
    "source activate earthsim\n",
    "\n",
    "cd terrapin\n",
    "python setup.py develop\n",
    "cd ../quest\n",
    "python setup.py develop\n",
    "cd ../gsshapy\n",
    "python setup.py develop\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "import geopandas as gpd\n",
    "from gsshapy.modeling import GSSHAModel\n",
    "import quest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to automate the downloading process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_data(service_uri, bounds, collection_name):\n",
    "    \"\"\"\n",
    "    Downloads raster data from source uri and adds to a quest collection.\n",
    "    \n",
    "    If multiple raster tiles are retrieved for the given bounds it calls a quest \n",
    "    filter to merge the tiles into a single raster.\n",
    "    \"\"\"\n",
    "    \n",
    "    # download the features (i.e. locations) and metadata for the given web service\n",
    "    # the first time this is run it will take longer since it downloads \n",
    "    # and caches all metadata for the given service.\n",
    "    features = quest.api.search_catalog(uris=service_uri,\n",
    "                                      filters={'bbox': bounds},\n",
    "                                      as_dataframe=True,\n",
    "                                      )\n",
    "    \n",
    "    # add the selected features to a quest collection\n",
    "    added_features = quest.api.add_datasets(collection_name, features)\n",
    "    \n",
    "    # stage the data for download, optional parameters can be provided here \n",
    "    # for certain web services (i.e. date range etc), raster services don't \n",
    "    # typically have any optional parameters.\n",
    "    staged_datasets = quest.api.stage_for_download(uris=added_features)\n",
    "    \n",
    "    # download the staged datasets\n",
    "    quest.api.download_datasets(datasets=staged_datasets)\n",
    "    final_datasets = staged_datasets\n",
    "    \n",
    "    # if more than one raster tile downloaded, merge into a single raster tile\n",
    "    if len(staged_datasets) > 1:\n",
    "        merged_datasets = quest.api.run_tool(name='raster-merge',\n",
    "                                                 datasets=staged_datasets)\n",
    "        final_datasets = merged_datasets['datasets']\n",
    "        # delete the original individual tiles\n",
    "        quest.api.delete(staged_datasets)\n",
    "\n",
    "    # return file path of final geotiff\n",
    "    downloaded_datasets = quest.api.get_metadata(final_datasets)\n",
    "    downloaded_file_paths = [dataset['file_path'] for dataset\n",
    "                             in downloaded_datasets.values()]\n",
    "    return downloaded_file_paths[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters to change for the run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "elevation_service = 'svc://usgs-ned:13-arc-second'\n",
    "land_use_service = 'svc://usgs-nlcd:2011'\n",
    "land_use_grid_id = 'nlcd'\n",
    "base_dir = os.getcwd() # path needs to be absolute for gsshapy\n",
    "boundary_shapefile = os.path.join(base_dir, 'vicksburg_watershed', 'watershed_boundary.shp')\n",
    "gssha_model_name = 'vicksburg_south'\n",
    "gssha_model_directory = os.path.join(base_dir, gssha_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the download boundary from the shapefile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boundary_gpd = gpd.read_file(boundary_shapefile)\n",
    "bounds = [str(x) for x in boundary_gpd.geometry.bounds.values[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collection is where we will origanize the downloaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    quest.api.new_collection(gssha_model_name)\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data. This may take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "elevation_file_path = download_data(elevation_service, bounds, gssha_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "land_use_file_path = download_data(land_use_service, bounds, gssha_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the data to generate a GSSHA model. This may take a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the directory for the output\n",
    "try:\n",
    "    os.mkdir(gssha_model_directory)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "# generate GSSHA model files\n",
    "model = GSSHAModel(project_name=gssha_model_name,\n",
    "                   project_directory=gssha_model_directory,\n",
    "                   mask_shapefile=boundary_shapefile,\n",
    "                   elevation_grid_path=elevation_file_path,\n",
    "                   land_use_grid=land_use_file_path,\n",
    "                   land_use_grid_id=land_use_grid_id,\n",
    "                   out_hydrograph_write_frequency=1,\n",
    "                   )\n",
    "\n",
    "# add card for max depth\n",
    "model.project_manager.setCard('FLOOD_GRID',\n",
    "                              '{0}.fgd'.format(gssha_model_name),\n",
    "                              add_quotes=True)\n",
    "# TODO: Add depth grids to simulation\n",
    "# MAP_FREQ, DEPTH\n",
    "\n",
    "# add event for simulation\n",
    "model.set_event(simulation_start=datetime.utcnow(),\n",
    "                simulation_duration=timedelta(seconds=2*60),\n",
    "                rain_intensity=24,\n",
    "                rain_duration=timedelta(seconds=1*60),\n",
    "                )\n",
    "model.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
