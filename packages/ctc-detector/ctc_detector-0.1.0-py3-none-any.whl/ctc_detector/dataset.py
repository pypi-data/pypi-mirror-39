import os
import random
import json
import argparse
import numpy as np
from PIL import Image
from skimage.io import imread
from .config import config
from .helper import image_picker, get_ctc_nuclei_array, imshow
from .distribution import DistributionPolicyDataset
from . import transform as tx

"""
Input Directory Layout
data
└── train
    ├── group_1
    │   ├── sample_1
    │   │   ├── meta.json  (*1, sample-level)
    │   │   ├── 0_0 (e.g. grid index)
    │   │   │   ├── images
    │   │   │   │   ├── 0_0_DAPI.png   (*1, grid-level)
    │   │   │   │   ├── 0_0_EpCAM.png  (*1, grid-level)
    │   │   │   │   ├── 0_0_CD45.png   (*1, grid-level)
    │   │   │   │   ├── Segment.png    (*2, grid-level)
    │   │   │   │   ├── Contour.png    (*2, grid-level)
    │   │   │   │   └── Marker.png     (*2, grid-level)
    │   │   │   ├── meta.json (*1, grid-level)
    │   │   │   └── mask.csv  (*2, grid-level)
    │   │   ├── 0_1
    │   │   └── ...
    │   ├── sample_2
    │   ├── sample_3
    │   └── ...
    └── group_2

Note:
    1. (*1): Generated by individual preporcessor per partner software output
    2. (*2): Generated by nuclei_discovery.valid
    3. Training images are on-the-fly composed of image files suggested by image_picker,
       They are EpCAM/CD45/Segment for CTC's case
    4. Training labels are on-the-fly composed from grid-level meta.json and mask.csv

"""

class CTCDataset(DistributionPolicyDataset):
    def __init__(self, root, transform=None, cache=None, policy=None):
        super().__init__(root, policy)
        self.transform = transform
        self.cache = cache

    def __getitem__(self, idx):
        uid = self.samples[idx]
        if self.cache is not None and uid in self.cache:
            sample = self.cache[uid]
        else:
            fp = image_picker(self.root, uid, channel='CTC')
            # assert isinstance(fp, list)
            if not fp:
                raise FileNotFoundError(f"CTC's channel images not found! ({os.path.join(self.root, uid)})")
            # skimage.imread() handle TIFF file better than Pillow
            if isinstance(fp, list):
                channels = list(map(imread, fp))
                image = np.dstack(channels) # merge channels
            else:
                image = imread(fp)
            # overlay masks to single mask, maskes generated via mask.csv & meta.json
            size = image.shape[:2]
            csv_path = os.path.join(self.root, uid, 'mask.csv')
            label = get_ctc_nuclei_array(csv_path, size)
            sample = {'image': image,
                      'label': label,
                      'uid': uid,
                      'size': size}
            if self.cache is not None:
                self.cache[uid] = sample
        # apply transform
        if self.transform:
            image, label = sample['image'], sample['label']
            image, label = self.transform(image, label)
            sample = {'image': image,
                      'label': label,
                      'uid': sample['uid'],
                      'size': sample['size']}
        return sample

def run(dir, count):
    dir = dir.rstrip(os.sep)
    dataset = CTCDataset(dir)
    idx = random.randint(0, len(dataset)-1)
    sample = dataset[idx]
    print(sample['uid'])
    # display original image
    x, y = sample['image'], sample['label']
    imshow(x)
    imshow(y)
    input("Press Enter to continue...")

    transform = tx.Compose([
        tx.RandomScale(),
        tx.RandomChoice([
            tx.RandomTargetCrop(256),
            tx.RandomCrop(256)
        ]),
        tx.RandomVerticalFlip(),
        tx.RandomHorizontalFlip(),
        # tx.RandomRotate(),
        # tx.ElasticDistortion(),
        # tx.RandomNoise(),
        # tx.RandomGaussianBlur(),
        # map label pixel value to 0 or 1
        # tx.Lambda(lambda x, y: (x, np.where(y > 0.5, 1, 0))),
        # tx.ToTensor(),
        # tx.Normalize(),
    ])
    # display composed image
    for i in range(count):
        x_, y_ = transform(x, y)
        imshow(x_)
        imshow(y_)
        input(f"Press Enter to continue... {i+1}/{count}")

def main(args=None):
    parser = argparse.ArgumentParser(
        prog='insp_data'
    )
    parser.add_argument('--dir', type=str, action='store', help='dataset folder')
    parser.add_argument('--loop', type=int, help="number of loops")

    args = parser.parse_args(args)
    run(args.dir, args.loop)